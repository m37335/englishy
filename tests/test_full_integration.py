#!/usr/bin/env python3
"""
Full integration test for all AI modules in the Englishy pipeline.
Tests the complete research pipeline from query input to final report generation.
"""

import sys
import os
import pytest
import asyncio
from typing import Dict, Any

# Add src to path for imports
sys.path.append('/app/src')

def run_async_test(async_func, *args, **kwargs):
    """éåŒæœŸãƒ†ã‚¹ãƒˆã‚’åŒæœŸçš„ã«å®Ÿè¡Œã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°"""
    return asyncio.run(async_func(*args, **kwargs))

from ai.query_refiner import QueryRefiner
from ai.query_expander import QueryExpander
from ai.outline_creater import OutlineCreater
from ai.report_writer import (
    StreamLeadWriter, StreamSectionWriter, StreamConclusionWriter,
    StreamRelatedTopicsWriter, StreamReferencesWriter
)
from ai.mindmap_maker import MindMapMaker
from ai.grammar_analyzer import get_grammar_analyzer
from ai.llm_grammar_analyzer import LLMGrammarAnalyzer
from utils.lm import load_lm
from utils.web_retriever import load_web_retriever


class TestFullIntegration:
    """å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    @pytest.fixture
    def ai_modules(self):
        """å…¨AIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–"""
        try:
            lm = load_lm()
            
            return {
                'query_refiner': QueryRefiner(lm=lm),
                'query_expander': QueryExpander(lm=lm),
                'outline_creater': OutlineCreater(lm=lm),
                'lead_writer': StreamLeadWriter(lm=lm),
                'section_writer': StreamSectionWriter(lm=lm),
                'conclusion_writer': StreamConclusionWriter(lm=lm),
                'related_topics_writer': StreamRelatedTopicsWriter(lm=lm),
                'references_writer': StreamReferencesWriter(lm=lm),
                'mindmap_maker': MindMapMaker(lm=lm),
                'grammar_analyzer': get_grammar_analyzer(),
                'llm_grammar_analyzer': LLMGrammarAnalyzer(lm=lm),
                'web_retriever': load_web_retriever()
            }
        except Exception as e:
            pytest.skip(f"AI modules initialization failed: {e}")
    
    @pytest.fixture
    def sample_queries(self):
        """ãƒ†ã‚¹ãƒˆç”¨ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªãƒ¼"""
        return [
            "ä»®å®šæ³•éå»ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦ãã ã•ã„",
            "å—å‹•æ…‹ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦",
            "å‹•åè©ã¨ä¸å®šè©ã®é•ã„ã«ã¤ã„ã¦",
            "ç¾åœ¨å®Œäº†å½¢ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„",
            "é–¢ä¿‚ä»£åè©ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦"
        ]
    
    def test_complete_pipeline_basic_grammar(self, ai_modules, sample_queries):
        """åŸºæœ¬çš„ãªæ–‡æ³•é …ç›®ã§ã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
        query = sample_queries[0]  # ä»®å®šæ³•éå»
        
        try:
            # Step 1: Query Refinement
            print(f"\nğŸ” Step 1: Query Refinement for '{query}'")
            refined_query = ai_modules['query_refiner'].refine_query(query)
            print(f"Refined query: {refined_query}")
            assert refined_query is not None
            assert len(refined_query) > 0
            
            # Step 2: Query Expansion
            print(f"\nğŸ“ˆ Step 2: Query Expansion")
            expanded_topics = ai_modules['query_expander'].expand_query(query)
            print(f"Expanded topics: {expanded_topics}")
            assert expanded_topics is not None
            assert len(expanded_topics) > 0
            
            # Step 3: Grammar Analysis
            print(f"\nğŸ“Š Step 3: Grammar Analysis")
            grammar_analysis = ai_modules['grammar_analyzer'].analyze_text(query)
            print(f"Grammar analysis: {grammar_analysis}")
            assert grammar_analysis is not None
            assert 'grammar_structures' in grammar_analysis
            
            # Step 4: Web Search (simulated)
            print(f"\nğŸŒ Step 4: Web Search (simulated)")
            search_results = [
                "Teaching Subjunctive Mood in ESL - Cambridge University Press",
                "English Grammar in Use - Raymond Murphy",
                "Practical English Usage - Michael Swan",
                "æ–‡éƒ¨ç§‘å­¦çœ è‹±èªæ•™è‚²ã®æ‰‹å¼•ã - æ–‡éƒ¨ç§‘å­¦çœ",
                "ä»®å®šæ³•ã®æŒ‡å°æ³• - æ±äº¬å¤§å­¦æ•™è‚²å­¦éƒ¨"
            ]
            print(f"Search results: {len(search_results)} items")
            
            # Step 5: Outline Creation
            print(f"\nğŸ“‹ Step 5: Outline Creation")
            outline = ai_modules['outline_creater'].create_outline(
                query=query,
                search_results=search_results,
                grammar_analysis=grammar_analysis
            )
            print(f"Outline created: {outline.title if hasattr(outline, 'title') else 'No title'}")
            assert outline is not None
            
            # Step 6: Report Generation
            print(f"\nğŸ“ Step 6: Report Generation")
            
            # Lead generation
            lead_text = ""
            async def generate_lead():
                nonlocal lead_text
                async for chunk in ai_modules['lead_writer'](query, outline.title, "Sample content"):
                    lead_text += chunk
            
            run_async_test(generate_lead)
            print(f"Lead generated: {len(lead_text)} characters")
            assert len(lead_text) > 0
            
            # Section generation (first section)
            if hasattr(outline, 'section_outlines') and outline.section_outlines:
                first_section = outline.section_outlines[0]
                section_text = ""
                keywords = ""
                if hasattr(first_section, 'subsection_outlines') and first_section.subsection_outlines:
                    if hasattr(first_section.subsection_outlines[0], 'keywords'):
                        keywords = ", ".join(first_section.subsection_outlines[0].keywords)
                
                async for chunk in ai_modules['section_writer'](
                    query, 
                    "\n".join(search_results), 
                    f"# {first_section.title}",
                    keywords
                ):
                    section_text += chunk
                print(f"Section generated: {len(section_text)} characters")
                assert len(section_text) > 0
            
            # Conclusion generation
            conclusion_text = ""
            async for chunk in ai_modules['conclusion_writer'](query, "Sample report content"):
                conclusion_text += chunk
            print(f"Conclusion generated: {len(conclusion_text)} characters")
            assert len(conclusion_text) > 0
            
            # Step 7: Related Topics Generation
            print(f"\nğŸ”— Step 7: Related Topics Generation")
            related_topics_text = ""
            keywords = ["ä»®å®šæ³•", "éå»å½¢", "would", "ifç¯€"]
            async for chunk in ai_modules['related_topics_writer'](
                query=query,
                outline_structure=outline,
                keywords=keywords,
                grammar_analysis=grammar_analysis
            ):
                related_topics_text += chunk
            print(f"Related topics generated: {len(related_topics_text)} characters")
            assert len(related_topics_text) > 0
            
            # Step 8: References Generation
            print(f"\nğŸ“š Step 8: References Generation")
            references_text = ""
            report_content = f"{lead_text}\n{section_text}\n{conclusion_text}"
            async for chunk in ai_modules['references_writer'](
                query=query,
                report_content=report_content,
                search_results="\n".join(search_results),
                outline_structure=outline,
                keywords=keywords
            ):
                references_text += chunk
            print(f"References generated: {len(references_text)} characters")
            assert len(references_text) > 0
            
            # Step 9: Mind Map Generation
            print(f"\nğŸ—ºï¸ Step 9: Mind Map Generation")
            mindmap_text = ""
            async for chunk in ai_modules['mindmap_maker'](
                report=report_content,
                outline_structure=outline,
                keywords=keywords,
                related_topics=related_topics_text
            ):
                mindmap_text += chunk
            print(f"Mind map generated: {len(mindmap_text)} characters")
            assert len(mindmap_text) > 0
            
            print(f"\nâœ… Complete pipeline test PASSED for '{query}'")
            
        except Exception as e:
            print(f"\nâŒ Pipeline test FAILED: {e}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            pytest.fail(f"Pipeline test failed: {e}")
    
    def test_complete_pipeline_passive_voice(self, ai_modules, sample_queries):
        """å—å‹•æ…‹ã§ã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
        query = sample_queries[1]  # å—å‹•æ…‹
        
        try:
            # Step 1: Query Refinement
            print(f"\nğŸ” Step 1: Query Refinement for '{query}'")
            refined_query = ai_modules['query_refiner'].refine_query(query)
            print(f"Refined query: {refined_query}")
            assert refined_query is not None
            
            # Step 2: Query Expansion
            print(f"\nğŸ“ˆ Step 2: Query Expansion")
            expanded_topics = ai_modules['query_expander'].expand_query(query)
            print(f"Expanded topics: {expanded_topics}")
            assert expanded_topics is not None
            
            # Step 3: Grammar Analysis
            print(f"\nğŸ“Š Step 3: Grammar Analysis")
            grammar_analysis = ai_modules['grammar_analyzer'].analyze_text(query)
            print(f"Grammar analysis: {grammar_analysis}")
            assert grammar_analysis is not None
            
            # Step 4: Web Search (simulated)
            print(f"\nğŸŒ Step 4: Web Search (simulated)")
            search_results = [
                "Teaching Passive Voice in ESL - Oxford University Press",
                "English Grammar in Use - Raymond Murphy",
                "Practical English Usage - Michael Swan",
                "æ–‡éƒ¨ç§‘å­¦çœ è‹±èªæ•™è‚²ã®æ‰‹å¼•ã - æ–‡éƒ¨ç§‘å­¦çœ",
                "å—å‹•æ…‹ã®æŒ‡å°æ³• - æ±äº¬å¤§å­¦æ•™è‚²å­¦éƒ¨"
            ]
            
            # Step 5: Outline Creation
            print(f"\nğŸ“‹ Step 5: Outline Creation")
            outline = ai_modules['outline_creater'].create_outline(
                query=query,
                search_results=search_results,
                grammar_analysis=grammar_analysis
            )
            assert outline is not None
            
            # Step 6: Report Generation
            print(f"\nğŸ“ Step 6: Report Generation")
            
            # Lead generation
            lead_text = ""
            async for chunk in ai_modules['lead_writer'](query, outline.title, "Sample content"):
                lead_text += chunk
            assert len(lead_text) > 0
            
            # Keywords for testing
            keywords = ["å—å‹•æ…‹", "beå‹•è©", "éå»åˆ†è©", "èƒ½å‹•æ…‹"]
            
            # Step 7: Related Topics Generation
            print(f"\nğŸ”— Step 7: Related Topics Generation")
            related_topics_text = ""
            async for chunk in ai_modules['related_topics_writer'](
                query=query,
                outline_structure=outline,
                keywords=keywords,
                grammar_analysis=grammar_analysis
            ):
                related_topics_text += chunk
            assert len(related_topics_text) > 0
            
            # Step 8: References Generation
            print(f"\nğŸ“š Step 8: References Generation")
            references_text = ""
            report_content = f"{lead_text}\nSample section content"
            async for chunk in ai_modules['references_writer'](
                query=query,
                report_content=report_content,
                search_results="\n".join(search_results),
                outline_structure=outline,
                keywords=keywords
            ):
                references_text += chunk
            assert len(references_text) > 0
            
            print(f"\nâœ… Complete pipeline test PASSED for '{query}'")
            return True
            
        except Exception as e:
            print(f"\nâŒ Pipeline test FAILED: {e}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            return False
    
    async def test_complete_pipeline_complex_grammar(self, ai_modules, sample_queries):
        """è¤‡é›‘ãªæ–‡æ³•é …ç›®ã§ã®å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""
        query = sample_queries[2]  # å‹•åè©ã¨ä¸å®šè©ã®é•ã„
        
        try:
            # Step 1: Query Refinement
            print(f"\nğŸ” Step 1: Query Refinement for '{query}'")
            refined_query = ai_modules['query_refiner'].refine_query(query)
            print(f"Refined query: {refined_query}")
            assert refined_query is not None
            
            # Step 2: Query Expansion
            print(f"\nğŸ“ˆ Step 2: Query Expansion")
            expanded_topics = ai_modules['query_expander'].expand_query(query)
            print(f"Expanded topics: {expanded_topics}")
            assert expanded_topics is not None
            
            # Step 3: Grammar Analysis
            print(f"\nğŸ“Š Step 3: Grammar Analysis")
            grammar_analysis = ai_modules['grammar_analyzer'].analyze_text(query)
            print(f"Grammar analysis: {grammar_analysis}")
            assert grammar_analysis is not None
            
            # Step 4: Web Search (simulated)
            print(f"\nğŸŒ Step 4: Web Search (simulated)")
            search_results = [
                "Teaching Gerunds and Infinitives - Oxford University Press",
                "English Grammar in Use - Raymond Murphy",
                "Practical English Usage - Michael Swan",
                "æ–‡éƒ¨ç§‘å­¦çœ è‹±èªæ•™è‚²ã®æ‰‹å¼•ã - æ–‡éƒ¨ç§‘å­¦çœ",
                "å‹•åè©ã¨ä¸å®šè©ã®æŒ‡å°æ³• - æ±äº¬å¤§å­¦æ•™è‚²å­¦éƒ¨"
            ]
            
            # Step 5: Outline Creation
            print(f"\nğŸ“‹ Step 5: Outline Creation")
            outline = ai_modules['outline_creater'].create_outline(
                query=query,
                search_results=search_results,
                grammar_analysis=grammar_analysis
            )
            assert outline is not None
            
            # Step 6: Report Generation
            print(f"\nğŸ“ Step 6: Report Generation")
            
            # Lead generation
            lead_text = ""
            async for chunk in ai_modules['lead_writer'](query, outline.title, "Sample content"):
                lead_text += chunk
            assert len(lead_text) > 0
            
            # Keywords for testing
            keywords = ["å‹•åè©", "ä¸å®šè©", "ingå½¢", "to + åŸå½¢", "ä½¿ã„åˆ†ã‘"]
            
            # Step 7: Related Topics Generation
            print(f"\nğŸ”— Step 7: Related Topics Generation")
            related_topics_text = ""
            async for chunk in ai_modules['related_topics_writer'](
                query=query,
                outline_structure=outline,
                keywords=keywords,
                grammar_analysis=grammar_analysis
            ):
                related_topics_text += chunk
            assert len(related_topics_text) > 0
            
            # Step 8: References Generation
            print(f"\nğŸ“š Step 8: References Generation")
            references_text = ""
            report_content = f"{lead_text}\nSample section content"
            async for chunk in ai_modules['references_writer'](
                query=query,
                report_content=report_content,
                search_results="\n".join(search_results),
                outline_structure=outline,
                keywords=keywords
            ):
                references_text += chunk
            assert len(references_text) > 0
            
            # Step 9: Mind Map Generation
            print(f"\nğŸ—ºï¸ Step 9: Mind Map Generation")
            mindmap_text = ""
            async for chunk in ai_modules['mindmap_maker'](
                report=report_content,
                outline_structure=outline,
                keywords=keywords,
                related_topics=related_topics_text
            ):
                mindmap_text += chunk
            assert len(mindmap_text) > 0
            
            print(f"\nâœ… Complete pipeline test PASSED for '{query}'")
            return True
            
        except Exception as e:
            print(f"\nâŒ Pipeline test FAILED: {e}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            return False
    
    def test_llm_grammar_analyzer_integration(self, ai_modules):
        """LLMãƒ™ãƒ¼ã‚¹æ–‡æ³•è§£æã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
        try:
            print(f"\nğŸ¤– Testing LLM-based Grammar Analyzer")
            
            # Test with different types of queries
            test_queries = [
                "If I had known, I would have helped you.",
                "The book was written by him.",
                "I enjoy reading books."
            ]
            
            for query in test_queries:
                print(f"\nTesting query: '{query}'")
                
                # LLM-based analysis
                llm_analysis = ai_modules['llm_grammar_analyzer'].analyze_text(query)
                print(f"LLM analysis: {llm_analysis}")
                
                # Regular analysis for comparison
                regular_analysis = ai_modules['grammar_analyzer'].analyze_text(query)
                print(f"Regular analysis: {regular_analysis}")
                
                # Both should return valid results
                assert llm_analysis is not None
                assert regular_analysis is not None
                assert 'grammar_structures' in llm_analysis
                assert 'grammar_structures' in regular_analysis
            
            print(f"\nâœ… LLM Grammar Analyzer integration test PASSED")
            return True
            
        except Exception as e:
            print(f"\nâŒ LLM Grammar Analyzer integration test FAILED: {e}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            return False
    
    def test_keyword_integration_throughout_pipeline(self, ai_modules):
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ©Ÿèƒ½ã®å…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆãƒ†ã‚¹ãƒˆ"""
        try:
            print(f"\nğŸ”‘ Testing Keyword Integration Throughout Pipeline")
            
            query = "ä»®å®šæ³•éå»ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦ãã ã•ã„"
            
            # Step 1: Grammar Analysis
            grammar_analysis = ai_modules['grammar_analyzer'].analyze_text(query)
            
            # Step 2: Outline Creation with keywords
            search_results = [
                "Teaching Subjunctive Mood in ESL - Cambridge University Press",
                "English Grammar in Use - Raymond Murphy"
            ]
            
            outline = ai_modules['outline_creater'].create_outline(
                query=query,
                search_results=search_results,
                grammar_analysis=grammar_analysis
            )
            
            # Verify keywords are present in outline
            if hasattr(outline, 'section_outlines') and outline.section_outlines:
                for section in outline.section_outlines:
                    if hasattr(section, 'subsection_outlines') and section.subsection_outlines:
                        for subsection in section.subsection_outlines:
                            if hasattr(subsection, 'keywords'):
                                print(f"Keywords in subsection '{subsection.title}': {subsection.keywords}")
                                assert len(subsection.keywords) > 0
            
            print(f"\nâœ… Keyword integration test PASSED")
            return True
            
        except Exception as e:
            print(f"\nâŒ Keyword integration test FAILED: {e}")
            import traceback
            print(f"Traceback: {traceback.format_exc()}")
            return False


class TestRealApplicationSimulation:
    """å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    def ai_modules(self):
        """å…¨AIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–"""
        try:
            lm = load_lm()
            
            return {
                'query_refiner': QueryRefiner(lm=lm),
                'query_expander': QueryExpander(lm=lm),
                'outline_creater': OutlineCreater(lm=lm),
                'lead_writer': StreamLeadWriter(lm=lm),
                'section_writer': StreamSectionWriter(lm=lm),
                'conclusion_writer': StreamConclusionWriter(lm=lm),
                'related_topics_writer': StreamRelatedTopicsWriter(lm=lm),
                'references_writer': StreamReferencesWriter(lm=lm),
                'mindmap_maker': MindMapMaker(lm=lm),
                'grammar_analyzer': get_grammar_analyzer(),
                'llm_grammar_analyzer': LLMGrammarAnalyzer(lm=lm),
                'web_retriever': load_web_retriever()
            }
        except Exception as e:
            pytest.skip(f"AI modules initialization failed: {e}")
    
    async def test_real_user_scenario_beginner(self, ai_modules):
        """åˆå¿ƒè€…ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®Ÿéš›ã®ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
        print(f"\nğŸ‘¤ Testing Real User Scenario: Beginner Level")
        
        # Simulate beginner user query
        query = "è‹±èªã®beå‹•è©ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„"
        
        try:
            # Complete pipeline execution
            result = await self._execute_complete_pipeline(ai_modules, query)
            
            # Verify beginner-friendly output
            assert result['lead_text'].find('beå‹•è©') >= 0 or result['lead_text'].find('be verb') >= 0
            assert len(result['lead_text']) > 100  # Sufficient content
            
            print(f"\nâœ… Beginner user scenario test PASSED")
            return True
            
        except Exception as e:
            print(f"\nâŒ Beginner user scenario test FAILED: {e}")
            return False
    
    async def test_real_user_scenario_advanced(self, ai_modules):
        """ä¸Šç´šè€…ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å®Ÿéš›ã®ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
        print(f"\nğŸ‘¤ Testing Real User Scenario: Advanced Level")
        
        # Simulate advanced user query
        query = "ä»®å®šæ³•éå»å®Œäº†ã¨ä»®å®šæ³•éå»ã®é•ã„ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„"
        
        try:
            # Complete pipeline execution
            result = await self._execute_complete_pipeline(ai_modules, query)
            
            # Verify advanced content
            assert result['lead_text'].find('ä»®å®šæ³•') >= 0
            assert len(result['lead_text']) > 150  # More detailed content
            
            print(f"\nâœ… Advanced user scenario test PASSED")
            return True
            
        except Exception as e:
            print(f"\nâŒ Advanced user scenario test FAILED: {e}")
            return False
    
    async def _execute_complete_pipeline(self, ai_modules, query):
        """å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ"""
        # Step 1: Query Refinement
        refined_query = ai_modules['query_refiner'].refine_query(query)
        
        # Step 2: Query Expansion
        expanded_topics = ai_modules['query_expander'].expand_query(query)
        
        # Step 3: Grammar Analysis
        grammar_analysis = ai_modules['grammar_analyzer'].analyze_text(query)
        
        # Step 4: Web Search (simulated)
        search_results = [
            "English Grammar in Use - Raymond Murphy",
            "Practical English Usage - Michael Swan",
            "æ–‡éƒ¨ç§‘å­¦çœ è‹±èªæ•™è‚²ã®æ‰‹å¼•ã - æ–‡éƒ¨ç§‘å­¦çœ"
        ]
        
        # Step 5: Outline Creation
        outline = ai_modules['outline_creater'].create_outline(
            query=query,
            search_results=search_results,
            grammar_analysis=grammar_analysis
        )
        
        # Step 6: Report Generation
        lead_text = ""
        async for chunk in ai_modules['lead_writer'](query, outline.title, "Sample content"):
            lead_text += chunk
        
        # Extract keywords from outline
        keywords = []
        if hasattr(outline, 'section_outlines') and outline.section_outlines:
            for section in outline.section_outlines:
                if hasattr(section, 'subsection_outlines') and section.subsection_outlines:
                    for subsection in section.subsection_outlines:
                        if hasattr(subsection, 'keywords'):
                            keywords.extend(subsection.keywords)
        
        # Step 7: Related Topics Generation
        related_topics_text = ""
        async for chunk in ai_modules['related_topics_writer'](
            query=query,
            outline_structure=outline,
            keywords=keywords,
            grammar_analysis=grammar_analysis
        ):
            related_topics_text += chunk
        
        # Step 8: References Generation
        references_text = ""
        report_content = f"{lead_text}\nSample section content"
        async for chunk in ai_modules['references_writer'](
            query=query,
            report_content=report_content,
            search_results="\n".join(search_results),
            outline_structure=outline,
            keywords=keywords
        ):
            references_text += chunk
        
        return {
            'refined_query': refined_query,
            'expanded_topics': expanded_topics,
            'grammar_analysis': grammar_analysis,
            'outline': outline,
            'lead_text': lead_text,
            'related_topics_text': related_topics_text,
            'references_text': references_text
        }


if __name__ == "__main__":
    print("ğŸ§ª Starting Full Integration Tests")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    pytest.main([__file__, "-v", "--tb=short"]) 