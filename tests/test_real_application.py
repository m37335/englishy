#!/usr/bin/env python3
"""
Real application test for Englishy.
Tests the actual application functionality and user scenarios.
"""

import sys
import os
import pytest

# Add src to path for imports
sys.path.append('/app/src')

from ai.query_refiner import QueryRefiner
from ai.query_expander import QueryExpander
from ai.outline_creater import OutlineCreater
from ai.grammar_analyzer import get_grammar_analyzer
from ai.llm_grammar_analyzer import LLMGrammarAnalyzer
from utils.lm import load_lm


class TestRealApplication:
    """å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    @pytest.fixture
    def ai_modules(self):
        """å…¨AIãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–"""
        try:
            lm = load_lm()
            
            return {
                'query_refiner': QueryRefiner(lm=lm),
                'query_expander': QueryExpander(lm=lm),
                'outline_creater': OutlineCreater(lm=lm),
                'grammar_analyzer': get_grammar_analyzer(),
                'llm_grammar_analyzer': LLMGrammarAnalyzer(lm=lm)
            }
        except Exception as e:
            pytest.skip(f"AI modules initialization failed: {e}")
    
    def test_real_user_query_processing(self, ai_modules):
        """å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªãƒ¼å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        print(f"\nğŸ‘¤ Testing Real User Query Processing")
        
        # å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãã†ãªã‚¯ã‚¨ãƒªãƒ¼
        real_user_queries = [
            "ä»®å®šæ³•éå»ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦ãã ã•ã„",
            "å—å‹•æ…‹ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦",
            "å‹•åè©ã¨ä¸å®šè©ã®é•ã„ã«ã¤ã„ã¦",
            "ç¾åœ¨å®Œäº†å½¢ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„",
            "é–¢ä¿‚ä»£åè©ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦",
            "è‹±èªã®beå‹•è©ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„",
            "ä»®å®šæ³•éå»å®Œäº†ã¨ä»®å®šæ³•éå»ã®é•ã„ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„"
        ]
        
        for i, query in enumerate(real_user_queries, 1):
            print(f"\n--- Test Case {i}: {query} ---")
            
            try:
                # Step 1: Query Refinement
                print(f"Step 1: Query Refinement")
                refined_query = ai_modules['query_refiner'].refine_query(query)
                print(f"  Refined: {refined_query}")
                assert refined_query is not None
                assert len(refined_query) > 0
                
                # Step 2: Query Expansion
                print(f"Step 2: Query Expansion")
                expanded_topics = ai_modules['query_expander'].expand_query(query)
                print(f"  Expanded: {len(expanded_topics)} topics")
                assert expanded_topics is not None
                assert len(expanded_topics) > 0
                
                # Step 3: Grammar Analysis
                print(f"Step 3: Grammar Analysis")
                grammar_analysis = ai_modules['grammar_analyzer'].analyze_text(query)
                print(f"  Grammar structures: {grammar_analysis['grammar_structures']}")
                assert grammar_analysis is not None
                assert 'grammar_structures' in grammar_analysis
                
                # Step 4: LLM Grammar Analysis
                print(f"Step 4: LLM Grammar Analysis")
                llm_analysis = ai_modules['llm_grammar_analyzer'].analyze_text(query)
                print(f"  LLM structures: {llm_analysis['grammar_structures']}")
                assert llm_analysis is not None
                assert 'grammar_structures' in llm_analysis
                
                # Step 5: Outline Creation
                print(f"Step 5: Outline Creation")
                search_results = [
                    "English Grammar in Use - Raymond Murphy",
                    "Practical English Usage - Michael Swan",
                    "æ–‡éƒ¨ç§‘å­¦çœ è‹±èªæ•™è‚²ã®æ‰‹å¼•ã - æ–‡éƒ¨ç§‘å­¦çœ"
                ]
                
                outline = ai_modules['outline_creater'].create_outline(
                    query=query,
                    search_results=search_results,
                    grammar_analysis=grammar_analysis
                )
                
                print(f"  Outline: {outline.title}")
                print(f"  Sections: {len(outline.section_outlines)}")
                
                # Verify outline structure
                assert outline is not None
                assert hasattr(outline, 'title')
                assert hasattr(outline, 'section_outlines')
                assert len(outline.section_outlines) > 0
                
                # Check keywords
                keyword_count = 0
                for section in outline.section_outlines:
                    if hasattr(section, 'subsection_outlines') and section.subsection_outlines:
                        for subsection in section.subsection_outlines:
                            if hasattr(subsection, 'keywords') and subsection.keywords:
                                keyword_count += len(subsection.keywords)
                                print(f"    Keywords in '{subsection.title}': {subsection.keywords}")
                
                print(f"  Total keywords: {keyword_count}")
                assert keyword_count > 0, "No keywords found in outline"
                
                print(f"âœ… Test Case {i} PASSED")
                
            except Exception as e:
                print(f"âŒ Test Case {i} FAILED: {e}")
                import traceback
                print(f"Traceback: {traceback.format_exc()}")
                pytest.fail(f"Test case {i} failed: {e}")
        
        print(f"\nâœ… Real user query processing test PASSED")
    
    def test_beginner_user_scenario(self, ai_modules):
        """åˆå¿ƒè€…ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
        print(f"\nğŸ“ Testing Beginner User Scenario")
        
        # åˆå¿ƒè€…ãŒå…¥åŠ›ã—ãã†ãªã‚¯ã‚¨ãƒªãƒ¼
        beginner_queries = [
            "è‹±èªã®beå‹•è©ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„",
            "ç¾åœ¨å½¢ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦",
            "è‹±èªã®åŸºæœ¬æ–‡æ³•ã‚’æ•™ãˆã¦ãã ã•ã„",
            "è‹±èªã®å‹‰å¼·æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„"
        ]
        
        for query in beginner_queries:
            print(f"\nTesting beginner query: '{query}'")
            
            # Query refinement
            refined_query = ai_modules['query_refiner'].refine_query(query)
            print(f"  Refined: {refined_query}")
            
            # Query expansion
            expanded_topics = ai_modules['query_expander'].expand_query(query)
            print(f"  Expanded topics: {len(expanded_topics)}")
            
            # Grammar analysis
            grammar_analysis = ai_modules['grammar_analyzer'].analyze_text(query)
            print(f"  Grammar structures: {grammar_analysis['grammar_structures']}")
            
            # Outline creation
            search_results = [
                "English Grammar in Use - Raymond Murphy",
                "Practical English Usage - Michael Swan",
                "æ–‡éƒ¨ç§‘å­¦çœ è‹±èªæ•™è‚²ã®æ‰‹å¼•ã - æ–‡éƒ¨ç§‘å­¦çœ"
            ]
            
            outline = ai_modules['outline_creater'].create_outline(
                query=query,
                search_results=search_results,
                grammar_analysis=grammar_analysis
            )
            
            print(f"  Outline: {outline.title}")
            print(f"  Sections: {len(outline.section_outlines)}")
            
            # Verify beginner-friendly content
            assert outline is not None
            assert len(outline.section_outlines) > 0
            
            # Check for basic grammar keywords
            basic_keywords = ["beå‹•è©", "ç¾åœ¨å½¢", "åŸºæœ¬", "å‹‰å¼·", "å­¦ç¿’"]
            found_basic_keywords = []
            
            for section in outline.section_outlines:
                if hasattr(section, 'subsection_outlines') and section.subsection_outlines:
                    for subsection in section.subsection_outlines:
                        if hasattr(subsection, 'keywords') and subsection.keywords:
                            for keyword in subsection.keywords:
                                if any(basic in keyword for basic in basic_keywords):
                                    found_basic_keywords.append(keyword)
            
            print(f"  Found basic keywords: {found_basic_keywords}")
        
        print(f"\nâœ… Beginner user scenario test PASSED")
    
    def test_advanced_user_scenario(self, ai_modules):
        """ä¸Šç´šè€…ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚·ãƒŠãƒªã‚ªãƒ†ã‚¹ãƒˆ"""
        print(f"\nğŸ¯ Testing Advanced User Scenario")
        
        # ä¸Šç´šè€…ãŒå…¥åŠ›ã—ãã†ãªã‚¯ã‚¨ãƒªãƒ¼
        advanced_queries = [
            "ä»®å®šæ³•éå»å®Œäº†ã¨ä»®å®šæ³•éå»ã®é•ã„ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„",
            "é–¢ä¿‚ä»£åè©ã®éåˆ¶é™ç”¨æ³•ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
            "è‹±èªã®å€’ç½®æ§‹æ–‡ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„",
            "è‹±èªã®å¼·èª¿æ§‹æ–‡ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"
        ]
        
        for query in advanced_queries:
            print(f"\nTesting advanced query: '{query}'")
            
            # Query refinement
            refined_query = ai_modules['query_refiner'].refine_query(query)
            print(f"  Refined: {refined_query}")
            
            # Query expansion
            expanded_topics = ai_modules['query_expander'].expand_query(query)
            print(f"  Expanded topics: {len(expanded_topics)}")
            
            # Grammar analysis
            grammar_analysis = ai_modules['grammar_analyzer'].analyze_text(query)
            print(f"  Grammar structures: {grammar_analysis['grammar_structures']}")
            
            # LLM analysis for advanced content
            llm_analysis = ai_modules['llm_grammar_analyzer'].analyze_text(query)
            print(f"  LLM structures: {llm_analysis['grammar_structures']}")
            
            # Outline creation
            search_results = [
                "Advanced English Grammar - Cambridge University Press",
                "English Grammar in Use Advanced - Raymond Murphy",
                "Practical English Usage - Michael Swan",
                "æ–‡éƒ¨ç§‘å­¦çœ è‹±èªæ•™è‚²ã®æ‰‹å¼•ã - æ–‡éƒ¨ç§‘å­¦çœ"
            ]
            
            outline = ai_modules['outline_creater'].create_outline(
                query=query,
                search_results=search_results,
                grammar_analysis=grammar_analysis
            )
            
            print(f"  Outline: {outline.title}")
            print(f"  Sections: {len(outline.section_outlines)}")
            
            # Verify advanced content
            assert outline is not None
            assert len(outline.section_outlines) > 0
            
            # Check for advanced grammar keywords
            advanced_keywords = ["ä»®å®šæ³•", "é–¢ä¿‚ä»£åè©", "å€’ç½®", "å¼·èª¿", "å®Œäº†", "éåˆ¶é™"]
            found_advanced_keywords = []
            
            for section in outline.section_outlines:
                if hasattr(section, 'subsection_outlines') and section.subsection_outlines:
                    for subsection in section.subsection_outlines:
                        if hasattr(subsection, 'keywords') and subsection.keywords:
                            for keyword in subsection.keywords:
                                if any(advanced in keyword for advanced in advanced_keywords):
                                    found_advanced_keywords.append(keyword)
            
            print(f"  Found advanced keywords: {found_advanced_keywords}")
        
        print(f"\nâœ… Advanced user scenario test PASSED")
    
    def test_error_handling_and_edge_cases(self, ai_modules):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
        print(f"\nâš ï¸ Testing Error Handling and Edge Cases")
        
        # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ã‚¯ã‚¨ãƒªãƒ¼
        edge_case_queries = [
            "",  # ç©ºã®ã‚¯ã‚¨ãƒªãƒ¼
            "a",  # éå¸¸ã«çŸ­ã„ã‚¯ã‚¨ãƒªãƒ¼
            "è‹±èª",  # éå¸¸ã«çŸ­ã„æ—¥æœ¬èªã‚¯ã‚¨ãƒªãƒ¼
            "This is a very long query that contains many words and should test the system's ability to handle lengthy input without breaking or causing issues with the processing pipeline.",  # éå¸¸ã«é•·ã„ã‚¯ã‚¨ãƒªãƒ¼
            "ç‰¹æ®Šæ–‡å­—!@#$%^&*()_+{}|:<>?[]\\;'\",./",  # ç‰¹æ®Šæ–‡å­—
            "1234567890",  # æ•°å­—ã®ã¿
            "è‹±èª æ–‡æ³• ä»®å®šæ³• éå» å®Œäº† é–¢ä¿‚ä»£åè© å€’ç½® å¼·èª¿ éåˆ¶é™ ç”¨æ³• é•ã„ è©³ã—ã èª¬æ˜ æ•™ãˆã¦ ãã ã•ã„"  # é•·ã„æ—¥æœ¬èªã‚¯ã‚¨ãƒªãƒ¼
        ]
        
        for i, query in enumerate(edge_case_queries, 1):
            print(f"\n--- Edge Case {i}: '{query[:50]}{'...' if len(query) > 50 else ''}' ---")
            
            try:
                # Query refinement
                refined_query = ai_modules['query_refiner'].refine_query(query)
                print(f"  Refined: {refined_query}")
                
                # Query expansion
                expanded_topics = ai_modules['query_expander'].expand_query(query)
                print(f"  Expanded: {len(expanded_topics)} topics")
                
                # Grammar analysis
                grammar_analysis = ai_modules['grammar_analyzer'].analyze_text(query)
                print(f"  Grammar structures: {grammar_analysis['grammar_structures']}")
                
                # LLM analysis
                llm_analysis = ai_modules['llm_grammar_analyzer'].analyze_text(query)
                print(f"  LLM structures: {llm_analysis['grammar_structures']}")
                
                # Outline creation (only for non-empty queries)
                if query.strip():
                    search_results = [
                        "English Grammar in Use - Raymond Murphy",
                        "Practical English Usage - Michael Swan"
                    ]
                    
                    outline = ai_modules['outline_creater'].create_outline(
                        query=query,
                        search_results=search_results,
                        grammar_analysis=grammar_analysis
                    )
                    
                    print(f"  Outline created: {outline.title if outline else 'None'}")
                
                print(f"âœ… Edge Case {i} handled successfully")
                
            except Exception as e:
                print(f"âŒ Edge Case {i} failed: {e}")
                # Edge cases should be handled gracefully, but some failures are expected
                if not query.strip():
                    print(f"  Expected failure for empty query")
                else:
                    print(f"  Unexpected failure")
        
        print(f"\nâœ… Error handling and edge cases test PASSED")
    
    def test_performance_and_stability(self, ai_modules):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨å®‰å®šæ€§ã®ãƒ†ã‚¹ãƒˆ"""
        print(f"\nâš¡ Testing Performance and Stability")
        
        # è¤‡æ•°ã®ã‚¯ã‚¨ãƒªãƒ¼ã‚’é€£ç¶šã§å‡¦ç†
        test_queries = [
            "ä»®å®šæ³•éå»ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦ãã ã•ã„",
            "å—å‹•æ…‹ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦",
            "å‹•åè©ã¨ä¸å®šè©ã®é•ã„ã«ã¤ã„ã¦",
            "ç¾åœ¨å®Œäº†å½¢ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦ãã ã•ã„",
            "é–¢ä¿‚ä»£åè©ã®ä½¿ã„æ–¹ã‚’æ•™ãˆã¦"
        ]
        
        import time
        
        for i, query in enumerate(test_queries, 1):
            print(f"\n--- Performance Test {i}: {query} ---")
            
            start_time = time.time()
            
            try:
                # Query refinement
                refined_query = ai_modules['query_refiner'].refine_query(query)
                
                # Query expansion
                expanded_topics = ai_modules['query_expander'].expand_query(query)
                
                # Grammar analysis
                grammar_analysis = ai_modules['grammar_analyzer'].analyze_text(query)
                
                # LLM analysis
                llm_analysis = ai_modules['llm_grammar_analyzer'].analyze_text(query)
                
                # Outline creation
                search_results = [
                    "English Grammar in Use - Raymond Murphy",
                    "Practical English Usage - Michael Swan"
                ]
                
                outline = ai_modules['outline_creater'].create_outline(
                    query=query,
                    search_results=search_results,
                    grammar_analysis=grammar_analysis
                )
                
                end_time = time.time()
                processing_time = end_time - start_time
                
                print(f"  Processing time: {processing_time:.2f} seconds")
                print(f"  Refined query: {refined_query}")
                print(f"  Expanded topics: {len(expanded_topics)}")
                print(f"  Grammar structures: {len(grammar_analysis['grammar_structures'])}")
                print(f"  LLM structures: {len(llm_analysis['grammar_structures'])}")
                print(f"  Outline sections: {len(outline.section_outlines)}")
                
                # Performance assertions
                assert processing_time < 30.0, f"Processing took too long: {processing_time:.2f} seconds"
                assert refined_query is not None
                assert len(expanded_topics) > 0
                assert len(grammar_analysis['grammar_structures']) >= 0
                assert len(llm_analysis['grammar_structures']) >= 0
                assert outline is not None
                
                print(f"âœ… Performance Test {i} PASSED")
                
            except Exception as e:
                print(f"âŒ Performance Test {i} FAILED: {e}")
                pytest.fail(f"Performance test {i} failed: {e}")
        
        print(f"\nâœ… Performance and stability test PASSED")


if __name__ == "__main__":
    print("ğŸ§ª Starting Real Application Tests")
    print("=" * 50)
    
    # ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    pytest.main([__file__, "-v", "--tb=short"]) 